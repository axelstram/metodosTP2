\section{Experimentación}

\subsection{Análisis de resultados para casos particulares}

A continuación, mostramos los resultados obtenidos de la comparación entre los algoritmos PageRank e IN-DEG para instancias particulares. Dichos resultados son la importancia de cada página j, es decir el $x_{j}$. \\

\begin{figure}[H]
\centering     %%% not \center
\subfigure[Figure A]{\label{fig:a}\includegraphics[width=0.4\linewidth]{imagenes/resultadosEstrella.png}}
\subfigure[Figure B]{\label{fig:b}\includegraphics[width=0.3\linewidth]{imagenes/estrella.png}}
\caption{Web con estructura de estrella.}
\end{figure}

En el caso de una web con forma de estrella, cabe destacar las páginas 1 y 2. La página 1 es referenciada por todas las demás, salvo la 2 que es referenciada por la página 1. Dado que IN-DEG definie el ranking de una página j en base a la cantidad de ejes entrantes, es claro que la página uno obtenga la primer posición y la página 2 la segunda posición. Las páginas restantes tienen ranking cero por no ser referenciadas por ninguna otra.
En cambio, para PageRank se hace visible la idea de qué tan importante es el que referencia, en vez de cuantos son los que referencian. Las páginas que no son linkeadas tienen una importancia baja en comparación a las primeras dos.


\begin{figure}[H]
\centering     %%% not \center
\subfigure[Figure A]{\label{fig:a}\includegraphics[width=0.4\linewidth]{imagenes/resultadosCompleto.png}}
\subfigure[Figure B]{\label{fig:b}\includegraphics[width=0.3\linewidth]{imagenes/completo.png}}
\caption{Web con estructura de pentágono.}
\end{figure}

El segundo ejemplo, un grafo completo de cinco nodos, lo hicimos para encontrar los casos en que los criterios de importancia de ambos algoritmos coinciden. Era esperable que todas las páginas tengan la misma importancia en ambos dos, ya que todas las páginas web son referenciadas por páginas con la misma importancia.

\begin{figure}[H]
\centering     %%% not \center
\subfigure[Figure A]{\label{fig:a}\includegraphics[width=0.3\linewidth]{imagenes/resultadosBinario.png}}
\subfigure[Figure B]{\label{fig:b}\includegraphics[width=0.5\linewidth]{imagenes/binario.png}}
\caption{Web con estructura de árbol binario.}
\end{figure}


\begin{figure}[H]
\centering     %%% not \center
\subfigure[Figure A]{\label{fig:a}\includegraphics[width=0.4\linewidth]{imagenes/resultadosCamino.png}}
\subfigure[Figure B]{\label{fig:b}\includegraphics[width=0.2\linewidth]{imagenes/camino.png}}
\caption{Web con estructura de camino.}
\end{figure}

En los dos últimos graficos, se puede apreciar un comportamiento similar a los primeros dos, ya que la estructura subyacente a ambos es similar a las de estos 2 gráficos, generándose rankings similares.   



\begin{figure}[H]
\centering     %%% not \center
\subfigure[Figure A]{\label{fig:a}\includegraphics[width=0.4\linewidth]{imagenes/resultadosArbolRecursivo.png}}
\subfigure[Figure B]{\label{fig:b}\includegraphics[width=0.4\linewidth]{imagenes/arbolRecursivo.png}}
\caption{Web con estructura de árbol recursivo.}
\end{figure}



\newpage



\begin{wrapfigure}{r}{0.6\textwidth}
  \vspace{-20pt}
  \begin{center}
    \includegraphics[scale= 0.6]{imagenes/pagerankVSindeg.png}
  \end{center}
  \vspace{-10pt}
  \vspace{-10pt}
\end{wrapfigure}

\subsection{Análisis de variación de resultados con distintos métodos}

Posteriormente, ejecutamos los algoritmos de $PageRank$ e $IN-DEG$ para una misma instancia de 500 páginas y 80000 links generada al azar. Queremos ver cuánto cambian los rankings de cada web para cada algoritmo. En el eje X está el puesto de las páginas según $PageRank$, y en el eje Y el valor del ranking de $IN-DEG$ para esa misma página (que está entre 0 y 1) multiplicado por una constante por cuestiones de claridad a la hora de visualizar el gráfico.\\


Podemos ver que en este caso particular, con una matriz bastante esparsa (30\% de los links aproximadamente), ambos algoritmos devuelven un resultado muy similar. Lo que varía es el puesto en PageRank de las webs que tienen pocos links entrantes de diferencia (varía mas en intervalos pequeños). En los casos particulares en donde hay muchas páginas apuntando a una, debería andar peor $IN-DEG$, lo cual no se aprecia en este gráfico ya que es un grafo muy esparso y es aleatorio, pero si en los ejemplos pequeños que vimos anteriormente.\\


\subsection{Análisis de convergencia de PageRank}
%Imagen 1
\begin{wrapfigure}{r}{0.6\textwidth}
  \vspace{-20pt}
  \begin{center}
    \includegraphics[scale= 0.6]{imagenes/convergencia1.png}
  \end{center}
  \vspace{-20pt}
   \caption{Con  1000 páginas y 3000 links.}
  \vspace{-10pt}
  \label{fig:img1}
\end{wrapfigure}

Para poder analizar la convergencia de PageRank realizamos mediciones de la cantidad de iteraciones que realiza el método de la potencia para el algoritmo, que termina cuando la norma de Manhattan es menor que un determinado valor muy cercano a 0.\\

Usamos tres instancias generadas al azar: La primera de 1000 páginas y 3000 links, la segunda de la misma cantidad de páginas pero 10000 links y la tercera de 500 páginas y 150000 links.\\

Nos interesa ver qué hace que el algoritmo termine en una menor cantidad de pasos y qué relación hay entre ese número y el valor de $c$. Ejecutamos $PageRank$ para cada instancia con una tolerancia fija de 0,00001, variando el valor del $c$ desde 0,001 hasta 0,999. Cada gráfico corresponde a los resultados obtenidos para una instancia distinta.\\



%Imagen 2
\begin{figure}[h]
  \includegraphics[scale= 0.6]{imagenes/convergencia2.png}
   \caption{Con  1000 páginas y  10000 links.}
  \label{fig:img1}
\end{figure}


\newpage

%Imagen 3
\begin{wrapfigure}{r}{0.6\textwidth}
  \vspace{-20pt}
  \begin{center}
    \includegraphics[scale= 0.6]{imagenes/convergencia3.png}
  \end{center}
  \vspace{-20pt}
   \caption{Con  500 páginas y  150000 links.}
  \vspace{-10pt}
  \label{fig:img1}
\end{wrapfigure}

Mirando cada gráfico por separado podemos ver que la cantidad de iteraciones del algoritmo disminuye mientras más chico sea el valor de $c$, independientemente de que tan esparsa sea la matriz de links. 
Si comparamos los tres gráficos, vemos que las normas son mas chicas y el algoritmo converge más rápidamente mientras mas completa (menos esparsa) sea la matriz de links.\\



%% FALTA ANALISIS DE POR QUE PASA ESTO %%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


Para ver como se comporta el algoritmo de $PageRank$ y comparar los resultados con los de $IN-DEG$, proponemos los siguientes ejemplos pequeños. Los grafos representan las páginas web y los link entre ellas, y las tablas muestran los resultados obtenidos de cada algoritmo.\\

%% ACA VAN LAS 6 IMAGENES DE GRAFOS , cada una junto a la tabla de resultados %%

%% ACA EL ANALISIS DE LOS RESULTADOS %%


\subsection{Análisis temporal de PageRank}

Para evaluar los tiempos del algoritmo PageRank con la estructura de matriz Vector que implementamos, generamos archivos de entradas de diferentes grafos. Son grafos generados aleatoriamente con cantidad de nodos desde 10 a 1000 y distintas cantidades de ejes de 10 a 1000. 
Ejecutamos el algoritmo para cada estructura y para cada uno de estos archivos de entrada. El siguiente gráfico muestra el tiempo obtenido en milisegundos dividido por la función $n^{2}$.\\


\begin{figure}[h]
  \includegraphics[scale= 0.4]{imagenes/complejidad-temporal-pagerank.png}
   \caption{Gráfico que representa el tiempo de corrida de PageRank con la estructura de datos Vector.}
  \label{fig:img1}
\end{figure}

El gráfico resultante es el de una función constante, lo que nos lleva a concluir que el algoritmo tiene una complejidad similar a O($n^{2}$).

\subsection{Comparación de performance del algoritmo sobre las distintas estructuras de datos}

El siguiente grafo detalla los resultados temporales de haber corrido instancias para PageRank con las estructuras de datos DOK, CSR y Vector. Son instancias con una cantidad determinada y ascendente de nodos, y un mismo nivel de esparcidad para todas las instancias.

\begin{figure}[h]
  \includegraphics[scale=0.4]{imagenes/comparacion-tiempo-ejecucion-csr-dok-vector.png}
   \caption{Gráfico que representa el tiempo de corrida de PageRank con distintas estructuras de datos.}
  \label{fig:img1}
\end{figure}

Pudimos observar que CSR fue el más rápido de los 3, ya que obtener los elementos y multiplicarlos es rápido, mientras que DOK es el más lento. A pesar de que tanto para CSR como DOK implementamos algoritmos más eficientes de multiplicación tanto para un escalar como para un vector, DOK resultó el más lento. \\

Creemos que esto se debe a la implementación interna de $map$ que está implementado sobre un Black-Red-tree. Tanto para multiplicar por un escalar como por un vector, iteramos por la estructura del mismo, de forma tal de aprovechar la esparcidad de la matriz y multiplicar sólo los elementos no nulos. En principio no encontramos una razón por la cual una implementación fuera mejor que la otra en cuanto a la forma de multiplicar desde el punto de vista algoritmico. Creemos que la razón radica en que, al iterar sobre los elementos de map se está haciendo una búsqueda binaria del próximo elemento en cada paso, dando como resultado que la complejidad de la operación no fuese $\mathcal{O}(nnz)$ sino $\mathcal{O}(nnz\log{}nnz)$ \\

Lo que nos resultó sorpresivo fue que incluso Vector tuvo una mejor performance que DOK, a pesar de que la complejidad de Vector para las operaciones anteriormente mencionadas es del orden cuadrático. Para este caso no pudimos obtener un resultado concluyente de por qué sucede esto. Una suposición a priori sugiere que se deba a optimizaciones realizadas por el compilador, explotando el hecho que Vector tenga todos sus elementos contiguos, disminuyendo así su tiempo de acceso. Sin embargo tal hipótesis excede nuestro análisis.\\
\newpage

Este otro gráfico también mide le tiempo de las tres estructuras pero en función de la esparcidad de la matriz. Se usaron matrices de tamaño fijo $140x140$ y se fue incrementando la cantidad de links haciendola cada vez menos esparsa.\\

\begin{wrapfigure}{r}{0.6\textwidth}
  \vspace{-20pt}
  \begin{center}
    \includegraphics[scale=0.4]{imagenes/MedicionTiempoEstructura.png}
  \end{center}
  \vspace{-20pt}
  \vspace{-10pt}
  \label{fig:img1}
\end{wrapfigure}

Vemos que para la estructura de CSR el tiempo es menor que el de la estructura vector para matrices muy esparsas, pero el tiempo para ambas estructuras es muy parecido cuando la matriz es poco esparsa. En cambio, cuando usamos la estructura de DOK, el tiempo dió mucho mayor para todas las instancias de matrices esparsas que generamos. Esto se debe, como dijimos anteriormente, a otros aspectos que no tienen que ver con la esparsidad de la matriz.\\

Por otro lado, en un punto vemos que el tiempo comienza a disminuir. Esto tiene que ver con la cantidad de iteraciones que realiza el algoritmo del método de la potencia.\\

\newpage

\subsection{Análisis de resultados de GeM y el método alternativo para ligas deportivas}

Para analizar los resultados de GeM y nuestro método alternativo, utilizamos los resultados reales de un torneo de fútbol (Torneo Final 2014 Argentina). Son 20 equipos, y cada uno de ellos juega una única vez con cada uno de los otros, a lo largo de 19 fechas de enfrentamientos. Los demás parámetros para ejecutar esta instancia fueron: 0.65 de probabilidad de teletransportación, 0.00001 de tolerancia para el método de la potencia. Más adelante analizaremos que sucede con los rankings cuando se varía la probabilidad de teletransportación.

En este caso, para cada equipo analizamos la posición en que quedaron en la última de las fechas con los dos algoritmos y las posiciones finales reales. En el siguiente gráfico vemos como variaron las posiciones. 


\begin{figure}[H]
  \includegraphics[scale=0.5]{imagenes/posicionesgem.png}
   \caption{Gráfico que compara las posiciones reales y las obtenidas con GeM y nuestro método alternativo.}
  \label{fig:img1}
\end{figure}

Las posiciones resultantes de nuestro método alternativo se asemejaron más a las posiciones reales, ya que ambos métodos de ranking utilizan la información de si se gana o no un partido y con cuántos goles. El método de GeM también tiene en cuenta el ranking del equipo contra el que se enfrentó. De manera que el impacto en el ranking de un equipo en una fecha depende del resultado de todos los partidos de esa fecha.

%%%%%%%%%%%%%ANALIZAR lOS PICOS

Ahora veamos como varían las posiciones obtenidas con GeM para algunos equipos a lo largo de ese mismo campeonato (fecha a fecha). Los resultados de cada fecha incluyen todos los partidos jugados hasta dicha fecha (incluidas todas las fechas anteriores).
Elegimos analizar los rankings solamente de aquellos equipos que nos resultó interesante estudiar en detalle.

\begin{figure}[H]
  \includegraphics[scale=0.449]{imagenes/gemfechas2.png}
   \caption{Gráfico que muestra los resultados de GeM fecha a fecha para algunos equipos.}
  \label{fig:img1}
\end{figure}

Vemos que los rankings de estos equipos varían mucho en las primeras fechas, pero a medida que transcurre el campeonato tienden a estabilizarse. Esto es porque la información nueva obtenida impacta de forma menos considerable en el resultado acumulado.\\

Los equipos que elegimos para analizar son: el ganador en el ranking real (River Plate), el ganador en el ranking de GeM (Vélez Sarsfield), el equipo con variación máxima entre el ranking real y el ranking de GeM (Estudiantes), y otro equipo que nos llevó a resultados interesantes el comportamiento de GeM (Gimnasia y Esgrima).\\

Primero, analizaremos el caso de Gimnasia y Esgrima. Como se ve en el gráfico, tiene un gran crecimineto entre las fechas 3 y 6. En principio creíamos que era poque había ganado todos los partidos durante ese tiempo. Sin embargo esto no resulta ser así. En la fecha 4 empató, en la 5 ganó y en la 6 volvió a empatar. A pesar de esto, su ranking creció constantemente. Esto se debe a que en la fecha 2 le ganó a Newell's Old Boys 3 a 0. Además, Newell's Old Boys ganó dos partidos por una diferencia de 3 goles, y los otros dos partidos los empató. Por esta razón, creemos que Gimnasia y Esgrima crece en su ranking dado que le ganó a un equipo en fechas anteriores que en las subsiguientes fechas ganó por mucho. \\

Nos resultó muy dificultoso realizar un análisis detallado de por qué saldría campeón Vélez Sarsfield utilizando el método GeM en lugar de River Plate como sucede en el ranking oficial. El dato más destacable de la fecha que puede impactar en este resultado, es que Vélez Sarsfield hizo 34 goles y fue el equipo que más goles hizo durante todo el campeonato, seguido de River Plate con 28. La baja en el puntaje de River Plate se ve principalmente en las fechas 2, 3 y 4, dónde empata la primera y pierde las dos siguientes, momento a partir del cual empieza a subir su puntaje, pero no lo suficiente como para superar a Vélez Sarsfield. Por otro lado, Vélez aumenta considerablemente su posición en la fecha 7 donde le gana 3 a 1 a Belgrano, y en al fecha 10 le gana 5 a 1 a Gimnasia y Esgrima, momento a partir del cual su puntaje se estabiliza.\\

Por último, para el caso de Estudiantes, el cual se ubica en la tercera posición en el ranking oficial, sucede algo similar que en el caso de Vélez Sarsfield. Si ordenaramos los equipos por cantidad de goles, Estudiantes se ubicaría en la décima posición, siendo 11 la posición obtenida por GeM. A pesar de haber ganado 3 veces hasta la fecha 7, su ranking desciende constantemente. Esto se debe a que gana contra equipos que tienen ranking bajo, y empata o pierde contra equipos de mayor ranking. En la fecha 8, le gana a Gimnasia y Esgrima, que en ese momento es el equipo con mayor puntaje, favoreciendolo significativamente. Luego, no gana partidos contra equipos de mucho ranking, lo que no le permite crecer significativamente. La razón de la diferencia de posiciones radica en que, a pesar de ser el tercer equipo con mayor cantidad de victorias, estas victorias fueron contra equipos que no tienen tanto peso en el ranking, por lo tanto en el método GeM se ve perjudicado. \\
\\
Como conclusión, vemos que realizar un análisis de GeM no es sencillo dado que no sólo impacta los resultados de un equipo en particular en cada fecha, sino que todos los resultados impactan en el resultado de todos los demás, aún no habiendo jugado en contra. En el caso de los empates, el método de GeM no los considera pero igualmente un equipo puede ascender o descender en su posición por los resultados del resto de los partidos de la fecha. Sucede lo mismo aún habiendo ganado o perdido, por ejemplo en la fecha 12 donde Gimnasia y Esgrima le ganó a Olimpo y bajó su ranking, o en la fecha 8 donde Vélez Sarfield pierde contra Atlético de Rafaela e igualmente sube su posición. Sin embargo, se tiene un método donde ganar o perder contra uno u otro equipo no tiene el mismo peso que en el método oficial.


\subsection{Análisis de resultados variando la probabilidad de teletransportación en $PageRank$}

Generamos una instancia que representa los partidos de un torneo de algún deporte, con 10 equipos y 54 partidos en el que no se produjeron empates. Ejecutamos el algoritmo de $GeM$ para conseguir la tabla de posiciones, variando el valor del parámetro $c$ desde 0.01 hasta 0,99. El siguiente gráfico muestra para cada equipo, el puesto que consiguió en el torneo según el algoritmo que se utilizó para generar la tabla.\\



\begin{figure}[H]
\centering
\includegraphics[width=0.7\linewidth]{imagenes/variacionDeTablaGEM.png}
\end{figure}

% \begin{wrapfigure}{l}{0.6\textwidth}
%   \vspace{-20pt}
%   \begin{center}
%     \includegraphics[scale= 0.6]{imagenes/variacionDeTablaGEM.png}
%   \end{center}
%   \vspace{-10pt}
%   \vspace{-10pt}
% \end{wrapfigure}

Vemos que un valor de $c$ distinto puede variar el puesto de los equipos que tengan un rank similar. Es decir, el primer equipo siempre es el 4, ya que ganó todos los partidos por mucha diferencia, y sea cual sea el $c$ su puesto no cambiará. Lo mismo pasa con el equipo7, que perdió todos sus partidos por mucha diferencia de goles. En casos extremos como esos los resultados no varían, pero si en otros casos como el equipo 2 y el equipo 10 que alternan sus puestos.

Este es un ejemplo pequeño, pero si llevamos estos resultados a una escala mayor, el valor de $c$ resulta ser muy importante, porque esta elección puede variar considerablemente el resultado de un torneo.\\
